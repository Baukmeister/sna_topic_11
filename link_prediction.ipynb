{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting links in Social Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Like relation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "like_1 = pd.read_csv(\"data/engineered_features/Like_Features_day_1.csv\")\n",
    "like_2 = pd.read_csv(\"data/engineered_features/Like_Features_day_2.csv\")\n",
    "like_3 = pd.read_csv(\"data/engineered_features/Like_Features_day_3.csv\")\n",
    "like_4 = pd.read_csv(\"data/engineered_features/Like_Features_day_4.csv\")\n",
    "like_5 = pd.read_csv(\"data/engineered_features/Like_Features_day_5.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "common_1 = pd.read_csv(\"data/engineered_features/common_interest_day_1.csv\")\n",
    "common_2 = pd.read_csv(\"data/engineered_features/common_interest_day_2.csv\")\n",
    "common_3 = pd.read_csv(\"data/engineered_features/common_interest_day_3.csv\")\n",
    "common_4 = pd.read_csv(\"data/engineered_features/common_interest_day_4.csv\")\n",
    "common_1_3 = pd.read_csv(\"data/engineered_features/common_interest_combined_day_1_3.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Group Relation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "with open(\"data/engineered_features/G_features_postings_days_1-3.pkl\", \"rb\") as input_file:\n",
    "    G_1_3 = pickle.load(input_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Posting TFIDF + graph features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"data/engineered_features/postings_tfidf_and_graph_features_only_positive_days_1to3.pkl\", \"rb\") as input_file:\n",
    "    tfidf_pos_1_3 = pickle.load(input_file)\n",
    "\n",
    "with open(\"data/engineered_features/postings_tfidf_and_graph_features_only_positive_day_4_test.pkl\",\n",
    "          \"rb\") as input_file:\n",
    "    tfidf_pos_4_test = pickle.load(input_file)\n",
    "\n",
    "with open(\"data/engineered_features/postings_tfidf_and_graph_features_only_negative_days_1to3.pkl\", \"rb\") as input_file:\n",
    "    tfidf_neg_1_3 = pickle.load(input_file)\n",
    "\n",
    "with open(\"data/engineered_features/postings_tfidf_and_graph_features_only_negative_day_4_test.pkl\",\n",
    "          \"rb\") as input_file:\n",
    "    tfidf_neg_4_test = pickle.load(input_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process data for ML"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Downsample data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment paramters:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "TRAIN_SET_SPLIT_SIZE = 0.8\n",
    "TEST_SET_DOWN_FACTOR = 0.3\n",
    "TRAIN_SET_DOWN_FACTOR = 0.3\n",
    "TRAIN_SET_NEG_OVERBALANCE = 25\n",
    "PREDICTION_GOAL = \"DAY_4\"\n",
    "#PREDICTION_GOAL = \"SAME_DAY\"\n",
    "\n",
    "#Exludes long-running classifiers\n",
    "QUICK_RUN = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of the huge number of nodes execution of basic data handling takes long on commodity hardware. Therefore the data sets need to be reduced in size while keeping the characteristics of the orignal data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### For the common interest relationship"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "if PREDICTION_GOAL == \"SAME_DAY\":\n",
    "    com = common_1_3\n",
    "    com[\"label\"] = [1 if c > 0 else 0 for c in common_1_3[\"weight\"]]\n",
    "elif PREDICTION_GOAL == \"DAY_4\":\n",
    "    com_4 = common_4[[\"source\",\"target\",\"weight\"]]\n",
    "    merged_com = pd.merge(common_1_3, com_4, on=[\"source\",\"target\"], how=\"left\")\n",
    "    merged_com.rename(columns= {\"weight_y\": \"day_4_weight\"}, inplace=True)\n",
    "    merged_com['day_4_weight'] = merged_com['day_4_weight'].fillna(0)\n",
    "    com = merged_com\n",
    "    com[\"label\"] = [1 if c > 0 else 0 for c in merged_com[\"day_4_weight\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "com_train, com_test = train_test_split(com, train_size=TRAIN_SET_SPLIT_SIZE)\n",
    "\n",
    "com_test_downsample = resample(\n",
    "    com_test,\n",
    "    n_samples=int(com_test.shape[0] * TEST_SET_DOWN_FACTOR)\n",
    ")\n",
    "\n",
    "com_train_neg = com_train[com_train.label == 0]\n",
    "com_train_pos = com_train[com_train.label == 1]\n",
    "\n",
    "com_train_neg_downsample = resample(com_train_neg,\n",
    "                              n_samples=int(com_train_pos.shape[0] * TRAIN_SET_NEG_OVERBALANCE)\n",
    "                              )\n",
    "\n",
    "com_train_resampled = resample(\n",
    "    pd.concat([com_train_pos, com_train_neg_downsample]),\n",
    "    n_samples=int( (com_train_pos.shape[0] + com_train_neg_downsample.shape[0]) * TRAIN_SET_DOWN_FACTOR)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "com_train_resampled.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resampled data structure still contains over 200k links (not considering train set downscaling), but now the label imbalance is corrected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### For the like relationship"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if PREDICTION_GOAL == \"SAME_DAY\":\n",
    "    like_all = pd.concat([like_1, like_2, like_3, like_4, like_5])\n",
    "    like_all[\"label\"] = [1 if c > 0 else 0 for c in like_all[\"current_weight\"]]\n",
    "elif PREDICTION_GOAL == \"DAY_4\":\n",
    "    like_1_3 = pd.concat([like_1, like_2, like_3])\n",
    "\n",
    "    like_4 = like_4[[\"source\",\"target\",\"current_weight\"]]\n",
    "    merged_like = pd.merge(like_1_3, like_4, on=[\"source\",\"target\"], how=\"left\")\n",
    "    merged_like.rename(columns= {\"current_weight_y\": \"day_4_weight\"}, inplace=True)\n",
    "    merged_like['day_4_weight'] = merged_like['day_4_weight'].fillna(0)\n",
    "    like_all = merged_like\n",
    "    like_all[\"label\"] = [1 if c > 0 else 0 for c in like_all[\"day_4_weight\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "like_train, like_test = train_test_split(like_all, train_size=TRAIN_SET_SPLIT_SIZE)\n",
    "\n",
    "\n",
    "like_test_downsampled = resample(\n",
    "    like_test,\n",
    "    n_samples=int(like_test.shape[0] * TEST_SET_DOWN_FACTOR)\n",
    ")\n",
    "\n",
    "like_train_neg = like_train[like_train.label == 0]\n",
    "like_train_pos = like_train[like_train.label == 1]\n",
    "\n",
    "like_train_neg_downsampled = resample(like_train_neg,\n",
    "                                n_samples=int(like_train_pos.shape[0] * TRAIN_SET_NEG_OVERBALANCE)\n",
    "                                )\n",
    "like_train_resampled = resample(\n",
    "    pd.concat([like_train_pos, like_train_neg_downsampled]),\n",
    "    n_samples=int( (like_train_pos.shape[0] + like_train_neg_downsampled.shape[0]) * TRAIN_SET_DOWN_FACTOR)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "like_train_resampled.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resampled data structure still contains over 400k (not considering train set downscaling) links, but now the label imbalance is corrected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### For group relation using TFIDF\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if PREDICTION_GOAL == \"SAME_DAY\":\n",
    "    tfidf_all_train = pd.concat([tfidf_neg_1_3, tfidf_pos_1_3])\n",
    "    tfidf_all_test = pd.concat([tfidf_neg_4_test, tfidf_pos_4_test])\n",
    "    tfidf_all = pd.concat([tfidf_all_train, tfidf_all_test])\n",
    "elif PREDICTION_GOAL == \"DAY_4\":\n",
    "    tfidf_1_3 = pd.concat([tfidf_neg_1_3, tfidf_pos_1_3])\n",
    "    tfidf_4 = pd.concat([tfidf_neg_4_test, tfidf_pos_4_test])\n",
    "\n",
    "    tfidf_4 = tfidf_4[[\"Source_User\",\"Target_User\",\"label\"]]\n",
    "\n",
    "    merged_tfidf = pd.merge(tfidf_1_3, tfidf_4, on=[\"Source_User\",\"Target_User\"], how=\"left\")\n",
    "    merged_tfidf.rename(columns= {\"label_y\": \"label\"}, inplace=True)\n",
    "    merged_tfidf['label'] = merged_tfidf['label'].fillna(0)\n",
    "    tfidf_all = merged_tfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidf_train, tfidf_test = train_test_split(tfidf_all, train_size=TRAIN_SET_SPLIT_SIZE)\n",
    "\n",
    "\n",
    "tfidf_test_downsampled = resample(\n",
    "    tfidf_test,\n",
    "    n_samples=int(tfidf_test.shape[0] * TEST_SET_DOWN_FACTOR)\n",
    ")\n",
    "\n",
    "tfidf_train_neg = tfidf_train[tfidf_train.label == 0]\n",
    "tfidf_train_pos = tfidf_train[tfidf_train.label == 1]\n",
    "\n",
    "tfidf_train_neg_downsampled = resample(tfidf_train_neg,\n",
    "                                n_samples=int(tfidf_train_pos.shape[0] * TRAIN_SET_NEG_OVERBALANCE)\n",
    "                                )\n",
    "tfidf_train_resampled = resample(\n",
    "    pd.concat([tfidf_train_pos, tfidf_train_neg_downsampled]),\n",
    "    n_samples=int( (tfidf_train_pos.shape[0] + tfidf_train_neg_downsampled.shape[0]) * TRAIN_SET_DOWN_FACTOR)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidf_train_resampled.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resampled data structure still contains over 90k (not considering train set downscaling) links, but now the label imbalance is corrected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define columns for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = \"label\"\n",
    "graph_features = [\n",
    "    \"jaccard_coef\",\n",
    "    \"adamic_adar_index\",\n",
    "    \"preferential_attachment_index\",\n",
    "    \"clustering_coefficient_score\"\n",
    "]\n",
    "larger_graph_features = [\n",
    "    \"jaccard_coef\",\n",
    "    \"adamic_adar_index\",\n",
    "    \"preferential_attachment_index\",\n",
    "    \"clustering_coefficient_score_Source_User\",\n",
    "    \"clustering_coefficient_score_Target_User\",\n",
    "    \"pagerank_Source_User\",\n",
    "    \"pagerank_Target_User\"\n",
    "]\n",
    "tfidf_features = [ f'{i}_TFIDF' for i in range(0,500)]\n",
    "\n",
    "\n",
    "X_train_com = com_train_resampled[graph_features]\n",
    "y_train_com = com_train_resampled[target]\n",
    "\n",
    "X_train_like = like_train_resampled[graph_features]\n",
    "y_train_like = like_train_resampled[target]\n",
    "\n",
    "X_train_tfidf = tfidf_train_resampled[larger_graph_features + tfidf_features]\n",
    "y_train_tfidf = tfidf_train_resampled[target]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_com = RandomForestClassifier(n_estimators=50, max_depth=40, random_state=0)\n",
    "svm_com = SVC()\n",
    "knn_com = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "rfc_like = RandomForestClassifier(n_estimators=50, max_depth=40, random_state=0)\n",
    "svm_like = SVC()\n",
    "knn_like = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "rfc_tfidf = RandomForestClassifier(n_estimators=50, max_depth=40, random_state=0)\n",
    "svm_tfidf = SVC()\n",
    "knn_tfidf = KNeighborsClassifier(n_neighbors=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define evaluation function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, actual):\n",
    "    return pd.DataFrame({\n",
    "        \"Measure\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"],\n",
    "        \"Score\": [accuracy_score(actual, predictions),\n",
    "                  precision_score(actual, predictions),\n",
    "                  recall_score(actual, predictions),\n",
    "                  f1_score(actual, predictions)]\n",
    "    }).transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit classifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_com.fit(X_train_com, y_train_com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_like.fit(X_train_like, y_train_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfc_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    svm_com.fit(X_train_com, y_train_com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    svm_like.fit(X_train_like, y_train_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    svm_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_com.fit(X_train_com, y_train_com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_like.fit(X_train_like, y_train_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_test_com = com_test_downsample[graph_features]\n",
    "y_test_com = com_test_downsample[target]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_like = like_test_downsampled[graph_features]\n",
    "y_test_like = like_test_downsampled[target]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf_test_downsampled[larger_graph_features + tfidf_features]\n",
    "y_test_tfidf = tfidf_test_downsampled[target]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RF evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = rfc_com.predict(X_test_com)\n",
    "evaluate_model(predictions, y_test_com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = rfc_like.predict(X_test_like)\n",
    "evaluate_model(predictions, y_test_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = rfc_tfidf.predict(X_test_tfidf)\n",
    "evaluate_model(predictions, y_test_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    predictions = svm_com.predict(X_test_com)\n",
    "    evaluate_model(predictions, y_test_com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    predictions = svm_like.predict(X_test_like)\n",
    "    evaluate_model(predictions, y_test_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not QUICK_RUN:\n",
    "    predictions = svm_tfidf.predict(X_test_tfidf)\n",
    "    evaluate_model(predictions, y_test_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = knn_com.predict(X_test_com)\n",
    "evaluate_model(predictions, y_test_com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = knn_like.predict(X_test_like)\n",
    "evaluate_model(predictions, y_test_like)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = knn_tfidf.predict(X_test_tfidf)\n",
    "evaluate_model(predictions, y_test_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "\n",
    "- Split according to days (one day for test one for verfication?)\n",
    "- Combine different features\n",
    "- Visuailze predited networks\n",
    "- Reformulate learning taks to predict the next day\n",
    "- Grid search for params\n",
    "- Cross validtation\n",
    "- Explainability?\n",
    "\n",
    "\n",
    "See this [repo](https://github.com/neo4j-examples/link-prediction) for reference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}